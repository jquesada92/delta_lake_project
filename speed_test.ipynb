{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4d750e5a-28c8-4223-98d1-e957154ef36a",
   "metadata": {},
   "outputs": [],
   "source": [
    "seconds_to_minutes = lambda x: x * 60\n",
    "run_every_minutes = seconds_to_minutes(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7437109-544a-4ee7-96df-d06ac7b55835",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/13 20:04:55 WARN HiveConf: HiveConf of name hive.stats.jdbc.timeout does not exist\n",
      "24/04/13 20:04:55 WARN HiveConf: HiveConf of name hive.stats.retries.wait does not exist\n",
      "24/04/13 20:04:56 WARN ObjectStore: Version information not found in metastore. hive.metastore.schema.verification is not enabled so recording the schema version 2.3.0\n",
      "24/04/13 20:04:56 WARN ObjectStore: setMetaStoreSchemaVersion called but recording version is disabled: version = 2.3.0, comment = Set by MetaStore hadoop@127.0.1.1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "MAIN_PATH = 'speed_test/'\n",
    "TEMP_PATH = f'{MAIN_PATH}temp/'\n",
    "WORKING_PATH= f'{MAIN_PATH}raw_data/'\n",
    "CHECK_POINT = f'{MAIN_PATH}_checkpoint'\n",
    "\n",
    "SCHEMA = 'speed_test'\n",
    "spark.sql(f\"CREATE SCHEMA IF NOT EXISTS {SCHEMA} \")\n",
    "\n",
    "BRONZE_TABLE = f'{SCHEMA}.speed_test_logs'\n",
    "spark.sql(f\"\"\"\n",
    "  CREATE EXTERNAL TABLE IF NOT EXISTS {BRONZE_TABLE} \n",
    "  (log_timestamp Timestamp\n",
    "  ) USING delta\n",
    "  LOCATION '{WORKING_PATH.replace('speed_test','speed_test.db')}'\n",
    "  TBLPROPERTIES (delta.enableChangeDataFeed = true)\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9a830fd5-782f-41e1-9dca-6918fe5f8dd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[key: string, value: string]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\n",
    "    \"set spark.databricks.delta.changeDataFeed.timestampOutOfRange.enabled = true;\"\n",
    ")\n",
    "spark.sql(\"set SQLConf.ADAPTIVE_EXECUTION_ENABLED.key= true\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f200c97-5c29-4374-aa66-5c8622964dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import *\n",
    "import pyspark.sql.functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d05fd82a-546d-4709-9796-dddb5d7ec45d",
   "metadata": {},
   "outputs": [],
   "source": [
    "streaming_logs_schema = StructType([StructField(\"download\",\n",
    "                    StructType([StructField(\"bandwidth\", LongType(), True),\n",
    "                                StructField(\"bytes\", LongType(), True),\n",
    "                                StructField(\"elapse\", LongType(), True),\n",
    "                                StructField(\"latency\", StringType(), True)])\n",
    "                                      , True),\n",
    "             StructField(\"interface\", StringType(), True),\n",
    "             StructField(\"isp\",StructType(), True),\n",
    "             StructField(\"ping\", StructType(), True),\n",
    "             StructField(\"result\", StructType([StructField(\"id\", StringType(), True),\n",
    "                                StructField(\"url\", StringType(), True),\n",
    "                                StructField(\"persisted\", BooleanType(), True),\n",
    "                               ]), True),\n",
    "             StructField(\"server\", StringType(), True),\n",
    "             StructField(\"timestamp\", TimestampType(), True),\n",
    "             StructField(\"type\", StringType(), True),\n",
    "             StructField(\"upload\", \n",
    "\n",
    "                    StructType([StructField(\"bandwidth\", LongType(), True),\n",
    "                                StructField(\"bytes\", LongType(), True),\n",
    "                                StructField(\"elapse\", LongType(), True),\n",
    "                                StructField(\"latency\", StringType(), True)]), True)\n",
    "                                ])\n",
    "\n",
    "\n",
    "streaming_logs_sdf = spark.readStream.schema(streaming_logs_schema)\\\n",
    "    .json(WORKING_PATH)\\\n",
    "            .select([F.col('result').getItem('id').alias('test_id'),\n",
    "                F.col(\"timestamp\").alias('log_timestamp'),\n",
    "                F.col('download').getItem('bytes').alias('download_bytes'),\n",
    "                F.col('upload').getItem('bytes').alias('upload_bytes')])\\\n",
    "    .withColumn('download_Mbytes',F.col('download_bytes')/1000000)\\\n",
    "        .withColumn('upload_Mbytes',F.col('upload_bytes')/1000000)\\\n",
    "        .withColumn('log_file',F.input_file_name())\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "03e10ad4-afb9-4014-a41e-718dceac6568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/13 20:04:57 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException\n",
      "24/04/13 20:04:59 WARN SparkStringUtils: Truncated the string representation of a plan since it was too large. This behavior can be adjusted by setting 'spark.sql.debug.maxToStringFields'.\n",
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_timestamp</th>\n",
       "      <th>test_id</th>\n",
       "      <th>download_bytes</th>\n",
       "      <th>upload_bytes</th>\n",
       "      <th>download_Mbytes</th>\n",
       "      <th>upload_Mbytes</th>\n",
       "      <th>log_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-13 19:30:49</td>\n",
       "      <td>1e5cfd5f-1171-4734-9502-4bbed0000931</td>\n",
       "      <td>481158816</td>\n",
       "      <td>18186880</td>\n",
       "      <td>481.158816</td>\n",
       "      <td>18.18688</td>\n",
       "      <td>file:///home/hadoop/deltalake/speed_test/raw_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-13 17:41:02</td>\n",
       "      <td>f1e2c384-026b-4f07-a240-bc9a6f0dff99</td>\n",
       "      <td>566126008</td>\n",
       "      <td>22625000</td>\n",
       "      <td>566.126008</td>\n",
       "      <td>22.62500</td>\n",
       "      <td>file:///home/hadoop/deltalake/speed_test/raw_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-13 19:08:48</td>\n",
       "      <td>34d24d69-24c2-427a-b185-f9546fa596cb</td>\n",
       "      <td>572540648</td>\n",
       "      <td>8101560</td>\n",
       "      <td>572.540648</td>\n",
       "      <td>8.10156</td>\n",
       "      <td>file:///home/hadoop/deltalake/speed_test/raw_d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        log_timestamp                               test_id  download_bytes  \\\n",
       "0 2024-04-13 19:30:49  1e5cfd5f-1171-4734-9502-4bbed0000931       481158816   \n",
       "1 2024-04-13 17:41:02  f1e2c384-026b-4f07-a240-bc9a6f0dff99       566126008   \n",
       "2 2024-04-13 19:08:48  34d24d69-24c2-427a-b185-f9546fa596cb       572540648   \n",
       "\n",
       "   upload_bytes  download_Mbytes  upload_Mbytes  \\\n",
       "0      18186880       481.158816       18.18688   \n",
       "1      22625000       566.126008       22.62500   \n",
       "2       8101560       572.540648        8.10156   \n",
       "\n",
       "                                            log_file  \n",
       "0  file:///home/hadoop/deltalake/speed_test/raw_d...  \n",
       "1  file:///home/hadoop/deltalake/speed_test/raw_d...  \n",
       "2  file:///home/hadoop/deltalake/speed_test/raw_d...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f'SELECT * FROM {BRONZE_TABLE} LIMIT 3').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2bd13f1b-f12a-496a-b26e-db0895a47699",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/04/13 20:05:01 WARN ResolveWriteToStream: spark.sql.adaptive.enabled is not supported in streaming DataFrames/Datasets and will be disabled.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pyspark.sql.streaming.query.StreamingQuery at 0x7fc7073d60e0>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "streaming_logs_sdf.writeStream.format('delta')\\\n",
    ".outputMode(\"append\")\\\n",
    ".option(\"checkpointLocation\", CHECK_POINT)\\\n",
    ".trigger(processingTime='0 seconds')\\\n",
    ".option(\"overwriteSchema\", \"true\")\\\n",
    ".option(\"mergeSchema\", \"true\")\\\n",
    ".toTable(BRONZE_TABLE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223e02f6-45b8-418b-bffe-c11a81fb1c36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cefa55bc-130e-42bb-984b-4b272df05669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess, sys\n",
    "import threading\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "import os\n",
    "from glob import glob\n",
    "os.makedirs(WORKING_PATH,exist_ok=True)\n",
    "\n",
    "\n",
    "def speed_test():\n",
    "    \n",
    "    def move_temp_to_raw():\n",
    "        files = glob(f'{TEMP_PATH}*.json')\n",
    "        list(map(lambda x: os.rename(x, x.replace(TEMP_PATH,WORKING_PATH)),files ))\n",
    "        \n",
    "    while True:\n",
    "        now = dt.now()\n",
    "        file_name =  f\"log_{now.strftime('%Y_%m_%d_%H_%M_%s')}.json\"\n",
    "        subprocess.run(f'touch {TEMP_PATH}{file_name} && speedtest --format=json >> {TEMP_PATH}{file_name} && mv  {TEMP_PATH}{file_name} {WORKING_PATH}{file_name}', shell = True, executable=\"/bin/bash\")\n",
    "        move_temp_to_raw()\n",
    "        time.sleep(run_every_minutes)\n",
    "        \n",
    "\n",
    "\n",
    "thread = threading.Thread(target=speed_test)\n",
    "thread.start()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "580d1fa3-5c99-4e01-9c95-d50b18011c6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2024-04-13 20:05:02.150] [error] Limit reached:\n",
      "\n",
      "Speedtest CLI. Too many requests received. To maintain a fair and stable environment, please review and adjust the frequency of your requests.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>log_timestamp</th>\n",
       "      <th>test_id</th>\n",
       "      <th>download_bytes</th>\n",
       "      <th>upload_bytes</th>\n",
       "      <th>download_Mbytes</th>\n",
       "      <th>upload_Mbytes</th>\n",
       "      <th>log_file</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2024-04-13 19:30:49</td>\n",
       "      <td>1e5cfd5f-1171-4734-9502-4bbed0000931</td>\n",
       "      <td>481158816</td>\n",
       "      <td>18186880</td>\n",
       "      <td>481.158816</td>\n",
       "      <td>18.18688</td>\n",
       "      <td>file:///home/hadoop/deltalake/speed_test/raw_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2024-04-13 17:41:02</td>\n",
       "      <td>f1e2c384-026b-4f07-a240-bc9a6f0dff99</td>\n",
       "      <td>566126008</td>\n",
       "      <td>22625000</td>\n",
       "      <td>566.126008</td>\n",
       "      <td>22.62500</td>\n",
       "      <td>file:///home/hadoop/deltalake/speed_test/raw_d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2024-04-13 19:08:48</td>\n",
       "      <td>34d24d69-24c2-427a-b185-f9546fa596cb</td>\n",
       "      <td>572540648</td>\n",
       "      <td>8101560</td>\n",
       "      <td>572.540648</td>\n",
       "      <td>8.10156</td>\n",
       "      <td>file:///home/hadoop/deltalake/speed_test/raw_d...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        log_timestamp                               test_id  download_bytes  \\\n",
       "0 2024-04-13 19:30:49  1e5cfd5f-1171-4734-9502-4bbed0000931       481158816   \n",
       "1 2024-04-13 17:41:02  f1e2c384-026b-4f07-a240-bc9a6f0dff99       566126008   \n",
       "2 2024-04-13 19:08:48  34d24d69-24c2-427a-b185-f9546fa596cb       572540648   \n",
       "\n",
       "   upload_bytes  download_Mbytes  upload_Mbytes  \\\n",
       "0      18186880       481.158816       18.18688   \n",
       "1      22625000       566.126008       22.62500   \n",
       "2       8101560       572.540648        8.10156   \n",
       "\n",
       "                                            log_file  \n",
       "0  file:///home/hadoop/deltalake/speed_test/raw_d...  \n",
       "1  file:///home/hadoop/deltalake/speed_test/raw_d...  \n",
       "2  file:///home/hadoop/deltalake/speed_test/raw_d...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(f'SELECT * FROM {BRONZE_TABLE} LIMIT 3').toPandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b7863f92-0b41-424a-a2a1-36c6da7f62fe",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7fc6ffd20d90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_bgcolor = \"#2c292d\"\n",
    "#paper_bgcolor =\"#211f22\"\n",
    "paper_bgcolor =\"#1a1d21\"\n",
    "download_color = \"#ab9df2\"\n",
    "upload_color = \"#78dce8\"\n",
    "default_fontcolor = \"white\"\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "from plotly.subplots import make_subplots\n",
    "from dash.dependencies import Input, Output\n",
    "from dash import dcc, html\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash\n",
    "\n",
    "\n",
    "def line_chart_download_vs_upload(fig,df):\n",
    "\n",
    "    x = df.log_timestamp\n",
    "\n",
    "\n",
    "    \n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x, y=df.upload_Mbytes, name=\"Upload (Mbps)\", line=dict(color=upload_color)\n",
    "        ),row =1, col=2,\n",
    "    )\n",
    "    fig.update_yaxes(\n",
    "    title_text=\"<b>Upload (Mbps)</b>\",\n",
    "    color=upload_color,\n",
    "    rangemode = 'tozero',\n",
    "     showgrid=False,\n",
    "    row =1, col=2,\n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    "    fig.add_trace(\n",
    "        go.Scatter(\n",
    "            x=x,\n",
    "            y=df.download_Mbytes,\n",
    "            name=\"Download (Mbps)\",\n",
    "            line=dict(color=download_color),\n",
    "\n",
    "        ),row =2, col=2,\n",
    "    )\n",
    "\n",
    "    fig.update_yaxes(\n",
    "        title_text=\"<b>Download (Mbps)</b>\",\n",
    "        color=download_color,\n",
    "        rangemode = 'tozero',\n",
    "         showgrid=False,\n",
    "        row =2, col=2,\n",
    "    )\n",
    "\n",
    "    fig.update_xaxes(\n",
    "        showgrid=False,\n",
    "    )\n",
    "\n",
    "    fig.update_layout(\n",
    "        plot_bgcolor=plot_bgcolor,\n",
    "        paper_bgcolor=paper_bgcolor,\n",
    "        font=dict(color=\"white\"),\n",
    "        legend=dict(orientation=\"h\", yanchor=\"bottom\", y=-0.15, xanchor=\"right\", x=1),\n",
    "    )\n",
    "   \n",
    "   \n",
    "\n",
    "\n",
    "def gauges_indicators(fig,value):\n",
    "\n",
    "    def gauge_chart(value, steps, title, color):\n",
    "        max_step = steps[-1][-1]\n",
    "        title = f\"{title} <span style='font-size:0.8em;color:gray'>MBps</span><br><span style='font-size:0.5em;color:gray'>Average</span>\"\n",
    "        gauge = go.Indicator(\n",
    "                mode=\"gauge+number+delta\",\n",
    "                value=value,\n",
    "                domain={\"x\": [0.25,0.55], \"y\":[0.25,0.55]},\n",
    "                title={\"text\": title, \"font\": {\"size\": 25},'align': 'center' },\n",
    "                delta={\"reference\": steps[-1][0],  \"font\": {\"size\": 13},\"increasing\": {\"color\": color}},\n",
    "                number={\"font\": {\"size\": 25}},\n",
    "                gauge={\n",
    "                \"axis\": {\n",
    "                    \"range\": [None, max_step],\n",
    "                    \"tickwidth\": 2,\n",
    "                    \"tickcolor\": plot_bgcolor,\n",
    "                },\n",
    "                \"bar\": {\"color\": color},\n",
    "                \"bgcolor\": \"white\",\n",
    "                \"borderwidth\": 2,\n",
    "                \"bordercolor\": \"gray\",\n",
    "                \"steps\": [\n",
    "                    {\"range\": steps[0], \"color\": \"#ff6188\"},\n",
    "                    {\"range\": steps[1], \"color\": \"#fc9867\"},\n",
    "                    {\"range\": steps[2], \"color\": \"#a9dc76\"},\n",
    "                ],\n",
    "            },\n",
    "            )\n",
    "        \n",
    "       \n",
    "        return gauge\n",
    "\n",
    "    \n",
    "    fig.add_trace( gauge_chart(\n",
    "        value[\"upload_Mbytes\"],\n",
    "        steps=[[0, 10], [10, 15], [15, 20]],\n",
    "        title=f\"<span style='font-size:0.8em;color:{upload_color}'>Upload</span>\",\n",
    "        color=upload_color,\n",
    "    ),row =1, col=1)\n",
    "\n",
    "    fig.add_trace(gauge_chart(\n",
    "        value[\"download_Mbytes\"],\n",
    "        steps=[[0, 450], [450, 600], [600, 700]],\n",
    "        title=f\"<span style='font-size:0.8em;color:{download_color}'>Download</span>\",\n",
    "        color=download_color,\n",
    "    )  ,row =2, col=1 )\n",
    "\n",
    "    fig.update_layout(\n",
    "            paper_bgcolor=paper_bgcolor,\n",
    "            font={\"color\": \"white\", \"family\": \"Arial\"},\n",
    "            showlegend=False\n",
    "        )\n",
    "    fig.update_traces(\n",
    "        number=dict(font=dict(size=28)),\n",
    "        delta=dict(font=dict(size=25))\n",
    "        )\n",
    "\n",
    "def multiplot_speedtest(df):\n",
    "\n",
    "    fig = make_subplots(\n",
    "    rows=2, cols=2,\n",
    "    specs=[\n",
    "            [{\"type\": \"domain\"}, {} ],\n",
    "            [ {\"type\": \"domain\"}, {}]\n",
    "    ],\n",
    "    column_widths = [0.30,0.70],\n",
    "    row_heights = [0.25,0.25],\n",
    "    horizontal_spacing=0.15,\n",
    "    vertical_spacing=0.15,\n",
    "          )\n",
    "    \n",
    "    values = df.iloc[-3:].mean()\n",
    "    gauges_indicators(fig,values)\n",
    "    line_chart_download_vs_upload(fig,df)\n",
    "    fig.update_layout(height=550, margin=dict(l=35,r=35,b=30,t=55))\n",
    "    \n",
    "    return fig\n",
    "\n",
    "    \n",
    "\n",
    "def register_Callback(app):\n",
    "    @app.callback(\n",
    "        Output(\"stream_line_chart\", \"figure\"),\n",
    "        [Input(\"interval-component\", \"n_intervals\"),\n",
    "        ],\n",
    "    )\n",
    "    def streamFig(intervals):\n",
    "\n",
    "        df = spark.read.table(BRONZE_TABLE).orderBy('log_timestamp',ascending=False).limit(10).toPandas().sort_values('log_timestamp',ascending=True)\n",
    "        return multiplot_speedtest(df)\n",
    "\n",
    "\n",
    "\n",
    "config = {\"displaylogo\": False, \"scrollZoom\": False, \"displayModeBar\": False}\n",
    "\n",
    "updates = dcc.Interval(\n",
    "    id=\"interval-component\", interval=10000, n_intervals=0  # in milliseconds\n",
    ")\n",
    "\n",
    "\n",
    "navbar = dbc.Navbar(\n",
    "    dbc.Container(\n",
    "        [\n",
    "            html.A(\n",
    "                # Use row and col to control vertical alignment of logo / brand\n",
    "                dbc.Row(\n",
    "                    [\n",
    "                        dbc.Col(html.Img(src=\"https://www.pinclipart.com/picdir/big/491-4917274_panama-flag-png-palestine-flag-vector-clipart.png\", height=\"30px\")),\n",
    "                        dbc.Col(dbc.NavbarBrand(\"Network Speed Test by Jose Quesada\", className=\"ms-2\")),\n",
    "                    ],\n",
    "                    align=\"center\",\n",
    "                    className=\"g-0\",\n",
    "                ),\n",
    "                href=\"https://plotly.com\",\n",
    "                style={\"textDecoration\": \"none\"},\n",
    "            ),\n",
    "            dbc.NavbarToggler(id=\"navbar-toggler\", n_clicks=0),\n",
    "            \n",
    "        ]\n",
    "    ),\n",
    "    color=paper_bgcolor,\n",
    "    dark=True,\n",
    ")\n",
    "\n",
    "\n",
    "streaming_col = dbc.Col(dcc.Graph(id=\"stream_line_chart\", config=config))\n",
    "\n",
    "layout = dbc.Container(\n",
    "    \n",
    "    [ navbar,\n",
    "    dbc.Container([updates,\n",
    "                    dcc.Store(id='last_32hrs'),\n",
    "                                dbc.Row(streaming_col), \n",
    "    ],\n",
    "            style={\n",
    "                \"background-color\": paper_bgcolor,\n",
    "                \"color\": default_fontcolor\n",
    "            })])\n",
    "\n",
    "app = dash.Dash(\n",
    "    external_stylesheets=[\n",
    "        \"https://cdn.jsdelivr.net/npm/bootstrap@4.3.1/dist/css/bootstrap.min.css\"\n",
    "    ],\n",
    ")\n",
    "#app.config.suppress_callback_exceptions = True\n",
    "app.layout = layout\n",
    "register_Callback(app)\n",
    "app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "66d0d526-356c-4cca-868f-13cb6d947182",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
